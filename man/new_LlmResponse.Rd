% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/01-LlmResponse-class.R
\name{new_LlmResponse}
\alias{new_LlmResponse}
\title{Create and Structure LLM Response Object}
\usage{
new_LlmResponse(api, prompt_settings)
}
\arguments{
\item{api}{An object of class LlmApi, created using new_RemoteLlmApi(), containing the API key, endpoint, and provider name.}

\item{prompt_settings}{An object of class LlmPromptSettings, containing prompt content, model, and tuning parameters
(e.g., temperature, max tokens).}
}
\value{
An object of class LlmResponse, which includes the following components:

- content: The raw API response returned from the model.
- provider: The name of the API provider (e.g., "OpenAI", "DeepSeek").
- prompt_settings: The unclassed list representation of the original prompt settings.
- generated_text: The primary response text content from the model.

If an error occurs during validation or request sending, an empty list is returned with an error attribute containing the error message.
}
\description{
The new_LlmResponse() function sends a prompt to a Large Language Model (LLM) API and returns a structured response object.
It integrates the credentials from an LlmApi object and the prompt configuration from an LlmPromptSettings object,
handles request errors gracefully, and returns the model-generated content along with associated metadata.
}
\examples{
api <- new_RemoteLlmApi(api_key_path = "path/to/key.txt", provider = "OpenAI")
prompt <- new_LlmPromptSettings(
  prompt_content = "Explain entropy in simple terms.",
  model = "gpt-3.5-turbo",
  temperature = 0.7
)
response <- new_LlmResponse(api, prompt)

if (!is.null(attr(response, "error"))) {
  cat("Error:", attr(response, "error"), "\n")
} else {
  cat("Model response:", response$generated_text, "\n")
}

}
\seealso{
[new_RemoteLlmApi()], [new_LlmPromptSettings()]]
}
