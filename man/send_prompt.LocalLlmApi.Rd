% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/01-LlmResponse-class.R
\name{send_prompt.LocalLlmApi}
\alias{send_prompt.LocalLlmApi}
\title{Send a prompt to a local llm API (e.g., Ollama)}
\usage{
\method{send_prompt}{LocalLlmApi}(api, prompt_settings)
}
\arguments{
\item{api}{An object of class LocalLlmApi, which contains the URL and model name for the local LLM API.}

\item{prompt_settings}{An object of class LlmPromptSettings, containing the prompt content and model parameters.}
}
\value{
A list containing the response from the Ollama API, structured similarly to OpenAI responses.
}
\description{
This function sends a prompt to the local LLM API (Ollama) and returns the response in a structured format.
}
\seealso{
[new_LlmResponse()]
}
